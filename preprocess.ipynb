{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import unicodedata\n",
    "import re\n",
    "import json\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from prepare import prep_create_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrangle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>is_remote</th>\n",
       "      <th>salary</th>\n",
       "      <th>post_date</th>\n",
       "      <th>date_accessed</th>\n",
       "      <th>job_description</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>ForMotiv</td>\n",
       "      <td>Remote</td>\n",
       "      <td>1</td>\n",
       "      <td>$75,000 - $120,000 a year</td>\n",
       "      <td>30+ days ago</td>\n",
       "      <td>2021-03-05</td>\n",
       "      <td>Has it ever occurred to you that as the Intern...</td>\n",
       "      <td>DS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Redzara.com</td>\n",
       "      <td>Remote</td>\n",
       "      <td>1</td>\n",
       "      <td>$35 - $80 an hour</td>\n",
       "      <td>10 days ago</td>\n",
       "      <td>2021-03-05</td>\n",
       "      <td>Only GC / EAD only. No C2CBackground screening...</td>\n",
       "      <td>DS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Nova Collective</td>\n",
       "      <td>Remote</td>\n",
       "      <td>1</td>\n",
       "      <td>$35 - $48 an hour</td>\n",
       "      <td>24 days ago</td>\n",
       "      <td>2021-03-05</td>\n",
       "      <td>Are you a data scientist who is really excited...</td>\n",
       "      <td>DS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Early Career Data Scientist - Applied Math</td>\n",
       "      <td>Pacific Northwest National Laboratory</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>1 day ago</td>\n",
       "      <td>2021-03-05</td>\n",
       "      <td>Organization and Job ID Job ID: 311747 Directo...</td>\n",
       "      <td>DS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AVP, Data Scientist</td>\n",
       "      <td>Synchrony</td>\n",
       "      <td>Alpharetta, GA 30005</td>\n",
       "      <td>1</td>\n",
       "      <td>$60,000 - $130,000 a year</td>\n",
       "      <td>7 days ago</td>\n",
       "      <td>2021-03-05</td>\n",
       "      <td>Job Description: Role Summary/Purpose: This ex...</td>\n",
       "      <td>DS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    job_title  \\\n",
       "0                              Data Scientist   \n",
       "1                              Data Scientist   \n",
       "2                              Data Scientist   \n",
       "3  Early Career Data Scientist - Applied Math   \n",
       "4                         AVP, Data Scientist   \n",
       "\n",
       "                                 company              location  is_remote  \\\n",
       "0                               ForMotiv                Remote          1   \n",
       "1                            Redzara.com                Remote          1   \n",
       "2                        Nova Collective                Remote          1   \n",
       "3  Pacific Northwest National Laboratory           Seattle, WA          0   \n",
       "4                              Synchrony  Alpharetta, GA 30005          1   \n",
       "\n",
       "                      salary     post_date date_accessed  \\\n",
       "0  $75,000 - $120,000 a year  30+ days ago    2021-03-05   \n",
       "1          $35 - $80 an hour   10 days ago    2021-03-05   \n",
       "2          $35 - $48 an hour   24 days ago    2021-03-05   \n",
       "3                                1 day ago    2021-03-05   \n",
       "4  $60,000 - $130,000 a year    7 days ago    2021-03-05   \n",
       "\n",
       "                                     job_description label  \n",
       "0  Has it ever occurred to you that as the Intern...    DS  \n",
       "1  Only GC / EAD only. No C2CBackground screening...    DS  \n",
       "2  Are you a data scientist who is really excited...    DS  \n",
       "3  Organization and Job ID Job ID: 311747 Directo...    DS  \n",
       "4  Job Description: Role Summary/Purpose: This ex...    DS  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json('indeed-data-jobs-FINAL.json')\n",
    "df = prep_create_labels(df).reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalize description text**: normalized text by lowercasing all letters, removes any inconsistencies in unicode character encoding, convert the resulting string to the ASCII character set. We'll ignore any errors in conversion, meaning we'll drop anything that isn't an ASCII character. Lastly,  turn the resulting bytes object back into a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = df.job_description[0]\n",
    "\n",
    "string = unicodedata.normalize('NFKD', string)\\\n",
    "             .encode('ascii', 'ignore')\\\n",
    "             .decode('utf-8', 'ignore')\n",
    "string = re.sub(r'[^\\w\\s]', '', string).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tokenize description text:** break words and any punctuation left over into discrete units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = df.job_description[0]\n",
    "\n",
    "# Create tokenizer.\n",
    "tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "    \n",
    "# Use tokenizer\n",
    "string = tokenizer.tokenize(string, return_str=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stemming text**: use the base form of each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = df.job_description[0]\n",
    "\n",
    "# Create porter stemmer.\n",
    "ps = nltk.porter.PorterStemmer()\n",
    "\n",
    "# Use the stemmer to stem each word in the list of words we created by using split.\n",
    "stems = [ps.stem(word) for word in string.split()]\n",
    "\n",
    "# Join our lists of words into a string again and assign to a variable.\n",
    "string = ' '.join(stems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lemmatizing text**: he base form in this case is known as the root word, but not the root stem. The difference is that the root word is always a lexicographically correct word (present in the dictionary), but the root stem may not be so. Thus, root word, also known as the lemma, will always be present in the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = df.job_description[0]\n",
    "\n",
    "# Create the lemmatizer.\n",
    "wnl = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "# Use the lemmatizer on each word in the list of words we created by using split.\n",
    "lemmas = [wnl.lemmatize(word) for word in string.split()]\n",
    "\n",
    "# Join our list of words into a string again and assign to a variable.\n",
    "string = ' '.join(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove stopwords from text**: Words which have little or no significance, especially when constructing meaningful features from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = df.job_description[0]\n",
    "extra_words=[]\n",
    "exclude_words=[]\n",
    "\n",
    "# Create stopword_list.\n",
    "stopword_list = stopwords.words('english')\n",
    "\n",
    "# Remove 'exclude_words' from stopword_list to keep these in my text.\n",
    "stopword_list = set(stopword_list) - set(exclude_words)\n",
    "\n",
    "# Add in 'extra_words' to stopword_list.\n",
    "stopword_list = stopword_list.union(set(extra_words))\n",
    "\n",
    "# Split words in string.\n",
    "words = string.split()\n",
    "\n",
    "# Create a list of words from my string with stopwords removed and assign to variable.\n",
    "filtered_words = [word for word in words if word not in stopword_list]\n",
    "\n",
    "# Join words in the list back into strings and assign to a variable.\n",
    "string_without_stopwords = ' '.join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#string_without_stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_clean(string):\n",
    "    '''\n",
    "    This function takes in a string and\n",
    "    returns the string normalized.\n",
    "    '''\n",
    "    string = unicodedata.normalize('NFKD', string)\\\n",
    "             .encode('ascii', 'ignore')\\\n",
    "             .decode('utf-8', 'ignore')\n",
    "    string = re.sub(r'[^\\w\\s]', '', string).lower()\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(string):\n",
    "    '''\n",
    "    This function takes in a string and\n",
    "    returns a tokenized string.\n",
    "    '''\n",
    "    # Create tokenizer.\n",
    "    tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "    \n",
    "    # Use tokenizer\n",
    "    string = tokenizer.tokenize(string, return_str=True)\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(string):\n",
    "    '''\n",
    "    This function takes in a string and\n",
    "    returns a string with words stemmed.\n",
    "    '''\n",
    "    # Create porter stemmer.\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    \n",
    "    # Use the stemmer to stem each word in the list of words we created by using split.\n",
    "    stems = [ps.stem(word) for word in string.split()]\n",
    "    \n",
    "    # Join our lists of words into a string again and assign to a variable.\n",
    "    string = ' '.join(stems)\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(string):\n",
    "    '''\n",
    "    This function takes in string for and\n",
    "    returns a string with words lemmatized.\n",
    "    '''\n",
    "    # Create the lemmatizer.\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    \n",
    "    # Use the lemmatizer on each word in the list of words we created by using split.\n",
    "    lemmas = [wnl.lemmatize(word) for word in string.split()]\n",
    "    \n",
    "    # Join our list of words into a string again and assign to a variable.\n",
    "    string = ' '.join(lemmas)\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(string, extra_words=[], exclude_words=[]):\n",
    "    '''\n",
    "    This function takes in a string, optional extra_words and exclude_words parameters\n",
    "    with default empty lists and returns a string.\n",
    "    '''\n",
    "    # Create stopword_list.\n",
    "    stopword_list = stopwords.words('english')\n",
    "    \n",
    "    # Remove 'exclude_words' from stopword_list to keep these in my text.\n",
    "    stopword_list = set(stopword_list) - set(exclude_words)\n",
    "\n",
    "    # Add in 'extra_words' to stopword_list.\n",
    "    stopword_list = stopword_list.union(set(extra_words))\n",
    "    \n",
    "    # Split words in string.\n",
    "    words = string.split()\n",
    "    \n",
    "    # Create a list of words from my string with stopwords removed and assign to variable.\n",
    "    filtered_words = [word for word in words if word not in stopword_list]\n",
    "    \n",
    "    # Join words in the list back into strings and assign to a variable.\n",
    "    string_without_stopwords = ' '.join(filtered_words)\n",
    "    \n",
    "    return string_without_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_job_data(df, column, extra_words=[], exclude_words=[]):\n",
    "    '''\n",
    "    This function take in a df and the string name for a text column with \n",
    "    option to pass lists for extra_words and exclude_words and\n",
    "    returns a df with the text article title, original text, stemmed text,\n",
    "    lemmatized text, cleaned, tokenized, & lemmatized text with stopwords removed.\n",
    "    '''\n",
    "    # drops duplicates but keeps the first instance\n",
    "    df = df.drop_duplicates(subset=None, keep='first')\n",
    "\n",
    "    df['clean'] = df[column].apply(basic_clean)\\\n",
    "                            .apply(tokenize)\\\n",
    "                            .apply(remove_stopwords, \n",
    "                                   extra_words=extra_words, \n",
    "                                   exclude_words=exclude_words)\\\n",
    "                            .apply(lemmatize)\n",
    "    \n",
    "    df['stemmed'] = df[column].apply(basic_clean).apply(stem)\n",
    "    \n",
    "    df['lemmatized'] = df[column].apply(basic_clean).apply(lemmatize)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prep_job_data(df, 'job_description', extra_words=['job', 'description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>is_remote</th>\n",
       "      <th>salary</th>\n",
       "      <th>post_date</th>\n",
       "      <th>date_accessed</th>\n",
       "      <th>job_description</th>\n",
       "      <th>label</th>\n",
       "      <th>clean</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>SmileDirectClub</td>\n",
       "      <td>Nashville, TN 37219</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>2 days ago</td>\n",
       "      <td>2021-03-05</td>\n",
       "      <td>Job Type: Full-Time Overview:  Marketing Analy...</td>\n",
       "      <td>DS</td>\n",
       "      <td>type fulltime overview marketing analytics dat...</td>\n",
       "      <td>job type fulltim overview market analyt data s...</td>\n",
       "      <td>job type fulltime overview marketing analytics...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>Data Science Engineer/Scientist</td>\n",
       "      <td>Baker Hughes</td>\n",
       "      <td>Minden, NV 89423</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>4 days ago</td>\n",
       "      <td>2021-03-05</td>\n",
       "      <td>Role Summary: The Data Science Engineer will s...</td>\n",
       "      <td>DE</td>\n",
       "      <td>role summary data science engineer support ana...</td>\n",
       "      <td>role summari the data scienc engin will suppor...</td>\n",
       "      <td>role summary the data science engineer will su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Ford Motor Company</td>\n",
       "      <td>Dearborn, MI</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>1 day ago</td>\n",
       "      <td>2021-03-05</td>\n",
       "      <td>Dearborn Ford Motor Company GDIA Job Descripti...</td>\n",
       "      <td>DE</td>\n",
       "      <td>dearborn ford motor company gdia qualification...</td>\n",
       "      <td>dearborn ford motor compani gdia job descript ...</td>\n",
       "      <td>dearborn ford motor company gdia job descripti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Piper Companies</td>\n",
       "      <td>Raleigh, NC</td>\n",
       "      <td>0</td>\n",
       "      <td>$135,000 - $145,000 a year</td>\n",
       "      <td>1 day ago</td>\n",
       "      <td>2021-03-05</td>\n",
       "      <td>Located in Raleigh NC, Piper Companies is seek...</td>\n",
       "      <td>DE</td>\n",
       "      <td>located raleigh nc piper company seeking data ...</td>\n",
       "      <td>locat in raleigh nc piper compani is seek a da...</td>\n",
       "      <td>located in raleigh nc piper company is seeking...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Inspire</td>\n",
       "      <td>Remote</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>30+ days ago</td>\n",
       "      <td>2021-03-05</td>\n",
       "      <td>Description:  WHAT YOU’LL BE DOING Do you have...</td>\n",
       "      <td>DS</td>\n",
       "      <td>youll intense curiosity interest data solving ...</td>\n",
       "      <td>descript what youll be do do you have an inten...</td>\n",
       "      <td>description what youll be doing do you have an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           job_title             company             location  \\\n",
       "207                   Data Scientist     SmileDirectClub  Nashville, TN 37219   \n",
       "545  Data Science Engineer/Scientist        Baker Hughes     Minden, NV 89423   \n",
       "466                    Data Engineer  Ford Motor Company         Dearborn, MI   \n",
       "429                    Data Engineer     Piper Companies          Raleigh, NC   \n",
       "114                   Data Scientist             Inspire               Remote   \n",
       "\n",
       "     is_remote                      salary     post_date date_accessed  \\\n",
       "207          0                                2 days ago    2021-03-05   \n",
       "545          0                                4 days ago    2021-03-05   \n",
       "466          0                                 1 day ago    2021-03-05   \n",
       "429          0  $135,000 - $145,000 a year     1 day ago    2021-03-05   \n",
       "114          1                              30+ days ago    2021-03-05   \n",
       "\n",
       "                                       job_description label  \\\n",
       "207  Job Type: Full-Time Overview:  Marketing Analy...    DS   \n",
       "545  Role Summary: The Data Science Engineer will s...    DE   \n",
       "466  Dearborn Ford Motor Company GDIA Job Descripti...    DE   \n",
       "429  Located in Raleigh NC, Piper Companies is seek...    DE   \n",
       "114  Description:  WHAT YOU’LL BE DOING Do you have...    DS   \n",
       "\n",
       "                                                 clean  \\\n",
       "207  type fulltime overview marketing analytics dat...   \n",
       "545  role summary data science engineer support ana...   \n",
       "466  dearborn ford motor company gdia qualification...   \n",
       "429  located raleigh nc piper company seeking data ...   \n",
       "114  youll intense curiosity interest data solving ...   \n",
       "\n",
       "                                               stemmed  \\\n",
       "207  job type fulltim overview market analyt data s...   \n",
       "545  role summari the data scienc engin will suppor...   \n",
       "466  dearborn ford motor compani gdia job descript ...   \n",
       "429  locat in raleigh nc piper compani is seek a da...   \n",
       "114  descript what youll be do do you have an inten...   \n",
       "\n",
       "                                            lemmatized  \n",
       "207  job type fulltime overview marketing analytics...  \n",
       "545  role summary the data science engineer will su...  \n",
       "466  dearborn ford motor company gdia job descripti...  \n",
       "429  located in raleigh nc piper company is seeking...  \n",
       "114  description what youll be doing do you have an...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
